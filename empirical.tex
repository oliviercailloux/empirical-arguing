\RequirePackage[l2tabu, orthodox]{nag}
\documentclass[version=3.21, pagesize, twoside=off, bibliography=totoc, DIV=calc, fontsize=12pt, a4paper, french, english]{scrartcl}
\input{preamble/packages}
\input{preamble/redac}
\input{preamble/math_basics}
\input{preamble/math_mine}

\usepackage{silence}
\WarningsOff[natbib]

%I find these settings useful in draft mode. Should be removed for final versions.
	%Which line breaks are chosen: accept worse lines, therefore reducing risk of overfull lines. Default = 200.
		\tolerance=2000
	%Accept overfull hbox up to...
		\hfuzz=2cm
	%Reduces verbosity about the bad line breaks.
		\hbadness 5000
	%Reduces verbosity about the underful vboxes.
		\vbadness=1300

\title{Study argument attacks empirically}
\author{Olivier Cailloux}
\affil{Université Paris-Dauphine, PSL Research University, CNRS, LAMSADE, 75016 PARIS, FRANCE\\
	\href{mailto:olivier.cailloux@dauphine.fr}{olivier.cailloux@dauphine.fr}
}
\author{Pierre Bisquert}
\affil{Affiliation}
\author{Nicolas Salliou}
\affil{Affiliation}
\author{Rallou Thomopoulos}
\affil{IATE, Univ Montpellier, INRAE, Institut Agro, MONTPELLIER, FRANCE\\
	\href{mailto:rallou.thomopoulos@inrae.fr}{rallou.thomopoulos@inrae.fr}
}
\hypersetup{
	pdfsubject={Argumentation},
	pdfkeywords={Position paper, Formal argumentation theory, Review, Logic-based argumentation},
}

\begin{document}
\maketitle

\section{Introduction}
\label{sec:intro}
Formal Argumentation Theory (FAT) \cite{Dung95} relies on “attacks” between arguments to compute most acceptable standpoints, in the form of the so-called “extensions”. These attacks are typically formalized as a binary relation considered as representing the directed contradiction or incompatibility status of pairs of arguments. In the vast majority of the articles in formal argumentation theory, the attacks are considered known, given to the analyst as a starting point of the study. 

In this sense, it is clear that arguments that are not attacked are of prominent importance for society, since they correspond to messages that received no objection and can therefore serve as a basis for compromise building \cite{MoulinBT2018}.{\commentOC{I think we can remove this?} }

In this position paper, we want to argue in favor of extending the scope of formal argumentation theory by relaxing this assumption. In particular, we argue that attacks should not necessarily be considered as representing an objective status of contradiction, as given for example by inspection of logical representation of arguments. We will give methodological and practical reasons to consider it of great importance to consider the attack relation as representing the subjective state of mind of an individual; and to study methods for obtaining information about this relation empirically.

Although some authors seem to acknowledge incidentally that attack relations sometimes can’t be considered known (cite Besnard \& Hunter), as we will see, few works in FAT avoid this assumption. One may think of at least two reasons for this apparent gap. First, to the best of our knowledge, the reasons for doubting this assumption have not been analyzed clearly. Second, there might be a lack of an idea of where to start if one relaxes this assumption, perhaps fearing that these questions would reveal hopelessly complex and that would be of interest only to the specific field of natural language processing. We provide here (partial) answers to these two points: we give reasons for doubting this assumpion; and we draw paths to study attack relations considered subjective that do not relate to natural language processing.

Preference based approaches still considers an attack relation, and the preference is supplementary data on top of the attack relation. (TODO: check Besnard \& Hunter - Elements of Argumentation, Chapter 6: Considering the Audience.) \commentRT{Transition sur preference-based approaches \`a expliquer car tombe comme un cheveu sur la soupe. 1) Subjective = related to a given audience, 2) Audiences introduced in (contextual) preference-based frameworks, 3) Cite different works (PAF, VAF ...)}

We want to distinguish between two attitudes towards the attack relations. 

The most usual attitude is what we call the \emph{a priori} attitude, reviewed in this section: the attack relations are considered known. They are deducible using a systematic procedure from the arguments. This covers several cases:
\begin{itemize}
\item the case where the arguments are considered given under a logic form and this is used to deduce the attack relations;
\item the case where the input itself is considered to be the attack relation;
\item and the case where the input is considered a set of arguments in natural language (NL), and the attack relations are deduced from these NL arguments. (One can think of text form, video, …)
\end{itemize}

Another attitude consists in considering the attack relations as empirical. Under that view, the attacks are revealed by something else than the arguments themselves and a priori knowledge, such as the reactions of individuals to the arguments, as we will propose.

Mention the study of \cite{ICCS2018} on comparisons of attacks? \commentRT{Faut-il ajouter les id\'ees suivantes : dans Yun et al. 2018 (ICCS) \`a partir d'un m\^eme ensemble d'arguments initial, 3 proc\'edures syst\'ematiques sont tour \`a tour appliqu\'ees pour d\'efinir les attaques ; puis les extensions sont calcul\'ees ; enfin les r\'esultats des 3 cas sont \'evalu\'es empiriquement par plusieurs groupes. L'objectif \'etant d'\'evaluer l'intuitivit\'e des 3 d\'efinitions.}

Besnard \& Hunter (Chapter 3, p. 38 to 39): “Note that we do not assume any metalevel information about formulae. In particular, we do not assume some preference ordering or ‘‘certainty ordering’’ over formulae. This is in contrast to numerous proposals for argumentation that do assume some form of ordering over formulae. Such orderings can be useful to resolve conflicts by, for example, selecting formulae from a more reliable source. However, this, in a sense, pushes the problem of dealing with conflicting information to one of finding and using orderings over formulae, and as such raises further questions such as the following: Where does the knowledge about reliability of the sources come from? How can it be assessed? How can it be validated?” \commentRT{Qu'est-ce qu'on conclut de cette citation ? Que Besnard \& Hunter ne supposent pas l'existence de pr\'ef\'erences ? Qu'ils n'envisagent pas l'attaque subjective ?}
In Chapter 4, they argue for an enlarged view. Selectivity is important. Impractical to represent every argument; some arguments are similar and can be summarized; readers do not want or can’t read many arguments and want a summary. They give multiple examples of situations where it is important to take into account the audience attitude towards the presented arguments.

\section{The usual perspective (in FAT?) about attacks}
\subsection{Classical logic}
Let $\Delta$ be a finite set of formulas is predicate logic with a deduction operator $⊢$. 
Given $\Phi \subseteq \Delta$, let ${\land}\Phi \subseteq \Delta$ denote the set of formulas that are conjunctions of all the formulas of $\Phi$ in whatever order (thus $\phi \in {\land}\Phi$ iff $\phi$ is a conjunction of formulas and the set of its conjuncts equals $\Phi$).
Given any $\Phi, \Psi \subseteq \Delta$, we write $\Psi ⊢ ¬{\land}\Phi$ iff $\exists \phi \in {\land}\Phi \suchthat \Psi ⊢ ¬\phi$, or equivalently, iff $\Phi ≠ \emptyset \land \forall \phi \in {\land}\Phi: \Psi ⊢ ¬\phi$, thus, whenever $\Psi$ permits to deduce that the formulas in $\Phi$ cannot all be satisfied.

An argument is a pair $(\Phi, \alpha)$ with $\Phi \subseteq \Delta$, called the support, and $\alpha \in \Delta$, called the conclusion, such that $\Phi ⊬ ⊥$ and such that $\Phi$ is a minimal subset of $\Delta$ satisfying $\Phi ⊢ \alpha$.

As the authors note, arguments are supposedly formalized making the enthymemes explicit (“An enthymeme is a form of reasoning in which some premises are implicit, most often because they are obvious” \citep[p.\ 41]{besnard_elements_2000}). They give the example “The baby no longer has her parents; therefore, she is an orphan”, which is formalized by making the further implicit claim explicit: “if a baby no longer has her parents, then she is an orphan”, which makes it a correct reasoning. 

An argument $(\Psi, \beta)$ \emph{defeats} $(\Phi, \alpha)$ iff $\beta ⊢ ¬{\land}\Phi'$ for some $\Phi' \subseteq \Phi$.

Given two formulas $\Phi, \Psi \in \Delta$, say that $\Psi$ is a canonical undercut for $\Phi$ iff $\Psi ⊢ ¬{\land}\Phi \land \forall \Psi' \subset \Psi: \Psi' ⊬ ¬{\land}\Phi$.

As the authors prove, the support of a defeater always admits a canonical undercut. Indeed, that some $(\Psi, \beta)$ defeats some argument with support $\Phi$ implies that $\Psi ⊢ ¬{\land}\Phi$, equivalently, that $\Psi$ and $\Phi$ together are unsatisfiable, equivalently, that $\Phi ⊢ ¬{\land}\Psi$. In the example, $\set{r, r → ¬p}$, the support of $b$, admits $\set{p}$ as canonical undercut, as $\set{p}$ permits to deduce $¬[r \land (r → ¬p)]$.

Given some set $N$, we represent a tree rooted at $n \in N$ using a pair $(n, s)$ where $s \subseteq N × N$ represents its successor relation (thus with $s$ acyclic). 
Canonical undercuts permit to associate to any $\Phi \subseteq \Delta$ its \emph{undercut tree} $U = (\Phi, u_\Phi)$, with $u_\Phi$ defined as follows. 
Given a node $\Psi$ in the tree, define $u_\Phi^{-1}[\Psi] \subseteq \Delta$ as the union of its ancestors (the brackets denote the reflexive and transitive closure); and define the successors of $\Psi$, $u_\Phi(\Psi)$, as the canonical undercutters $\Psi'$ for $\Psi$ that satisfy $\Psi' \nsubseteq u_\Phi^{-1}[\Psi]$.
We say that an undercut tree rooted at $\Phi$ argues for $\alpha$ whenever $\Phi ⊢ \alpha$.

\begin{example}
	$\Delta = \set{a, b, b → ¬a, c, c → ¬b}$. Here is an undercut tree arguing for $a$: root $\set{a}$, having child $\set{b, b → ¬a}$, itself having child $\set{c, c → ¬b}$. Here is an undercut tree arguing for $¬a$: root $\set{b, b → ¬a}$, with child ${c, c → ¬b}$.
\end{example}

Given a tree $T$, define the set $R$ of defeated nodes as the set such that $r \in R$ iff some successor of $r$ in $T$ is not in $R$.
One can see that this defines a unique set by observing that the definition determines the status of each node starting from the leaves down to the root: the leaves are undefeated, the predecessors of some leaf are defeated, and so on.

The authors propose to use the status of root nodes to determine arguments that are warranted.
In the above example, the root of our example tree arguing for $a$ is undefeated while the root of the tree arguing for $¬a$ is defeated. In fact, every undercut tree arguing for $a$ is undefeated while every undercut tree arguing for $¬a$ is defeated.

The following example features the famous Tweety, where we wonder whether Tweety can fly.
\begin{example}
	Our language uses the atoms: “Birds fly; Tweety is a bird; Tweety flies; Penguins are birds; Penguins do not fly”.
	$\Delta = \set{fly(birds), bird(Tw),\allowbreak fly(birds) \land bird(Tw) → flies(Tw), birds(pg), ¬fly(pg),\allowbreak birds(pg) \land ¬fly(pg) → ¬fly(birds)}$.
	An undercut tree arguing for $flies(Tw)$ is: root $\set{fly(birds),\allowbreak bird(Tw),\allowbreak fly(birds) \land bird(Tw) → flies(Tw)}$, having as child $\set{birds(pg),\allowbreak ¬fly(pg),\allowbreak birds(pg) \land ¬fly(pg) → ¬fly(birds)}$.
\end{example}
\commentOC{La conclusion semble changer radicalement si la base inclut aussi $¬¬fly(birds)$, par exemple. Aurais-je raté qqch. ?}

\subsection{PAFs}
\label{sec:pafs}
Here we talk about Preference-based Argumentation Frameworks.

Considering the book Rahwan, Simari - Argumentation in Artificial Intelligence (2009), Chapter 15: Argumentation for Decision Making, Amgoud.

We assume there is only one alternative on which to decide: $\dy$ or $\dn$ (e.g., surgery or do nothing). This simplifies the formal exposition without removing the crucial points of the propositions.

A decision system is $A_e, A_p^{\dy}, A_p^{\dn}, {≥_e}, {≥_p}, R_e, R_m$. 
\footnote{I assume that ${≥_m} = A_e × A_p$. Her section 2.2 suggests ${≥_m} = A_e × A_p$, Example 15.5 suggests ${≥_m} \subseteq A_e × A_p$; I assume the mistake is in the example. Also, $Def_m = R_m$ and $Def_e = R_e \cap (\overline{>_e})^{-1}$. $(\overline{>_e})^{-1}$ contains the pairs $(a, b)$ such that $a$ is strictly preferred to $b$ or they are indifferent or incomparable. $Def = (R_e \cap (\overline{>_e})^{-1}) \cup R_m = R.$}
Define $A_p = A_p^ {\dy} \cup A_p^{\dn}$.
Define $\allargs = A_e \cup A_p$ as the set of all arguments.

${≥_e} \subseteq A_e × A_e$, ${≥_p} \subseteq A_p × A_p$, both reflexive and transitive, the preferences.

$R_e \subseteq A_e × A_e$, $R_m \subseteq A_e × A_p$, the “objective” attacks. 

From $R = (R_e \setminus {<_e}) \cup R_m$, we obtain the extensions (an extension is a set of arguments). The stable and the preferred semantics are considered. Then the skeptically accepted arguments are $\cap E_i$ and the credulously accepted ones are $\cup E_i \setminus \cap E_i$.
\footnote{More from Amgoud: skept pref subseteq skept stable if not empty.}

$E$-acceptable = $E$-defended = all args that $E$ defends = those whose attackers are all attacked by $E$ = $\set{a \suchthat R^{-1}(a)\subseteq R(E)}$.

Conflict-free: contains no arguments that attack each other.
\footnote{More from Baroni and Giacomin: Admissible $E$: conflict-free and all included are $E$-defended; Complete $E$: $E$ admissible and includes every $E$-defended; Preferred: maximal admissible set, equivalently, maximal complete extensions. Stable: conflict-free and $E$ attacks all excluded args. Implies complete.}

Complete $E$: $E$ conflict-free and $E$ = $E$-defended.

Stable: conflict-free and $E$ attacks all excluded args. Implies maximally complete.

Preferred: maximal complete. Stable implies preferred. 

The semantics considered is: the stable ones if some exist; the preferred ones otherwise. Define $S$ as the skeptically accepted arguments in the resulting semantics, thus, $\cap E_i$ with the $E_i$ sets being the stable ones, or, if there is none, the preferred ones.

Given a set $A \subseteq \allargs$, say that $A$ is possibly failing iff $\exists B \subseteq \allargs$ with $B$ admissible and attacking every member of $A$ ($A \subseteq R(B)$).
Inversely, $A$ is necessarily resistant iff it is not possibly failing.

Interesting examples. $(5, 3), (3, 2), (2, 4), (4, 3), (2, 1), (1, d), (4, d)$. Here, 5 invalidates 3, which “suffices” to “resolve” the cycle as $(3, 2)$ “does not count” any more. Thus, 2 defends $d$ and $d$ is skeptically accepted. Also, consider: $(5, 4), (4, 3), (3, 2), (2, 4), (3, 1), (4, 1), (1, d)$. Without 5, $d$ is not sceptically accepted because 1 may be considered to resist thanks to the undecided status of the cycle, but with 5, $d$ becomes sceptically accepted as 1 is defeated.

\subsection{Defeasible logic}

\subsection{From text to logic arguments}
Should we devote a section to discuss proposals to “translate” NL to logic?

From Besnard \& Hunter - Elements of Argumentation, Chapter 1. “Numerous textbooks have explained how individual arguments, as found in the real world, can be represented and analyzed by classical logic. The focus of these books is on what constitutes a valid logical argument. A paragon of such a textbook by Fisher [Fis88] includes many examples of arguments originally presented in philosophy and in politics using free text, together with a comprehensive explanation of how they can be translated into propositional logic. However, these textbooks tend to circumvent the more difficult issues of inconsistency, conflict, and counterarguments.
To address these more difficult issues, an excellent starting point for considering monological argumentation is Toulmin’s book [Tou58], with developments of Toulmin’s approach having been reviewed by van Eemeren et al. [vGK87]. Toulmin’s work is regarded as a precursor to much of the formal developments in argumentation systems found in the artificial intelligence field. For reviews of formalisms for argumentation systems in artificial intelligence, see [PV02, CML00].” And more about this in their Section 4.9.

\section{Reasons not to consider it known}
We saw that most formal approaches in argumentation consider that the attack relation is (are) known. 
We here point out reasons to lift this assumption.

More precisely, we want to challenge the assumption, left implicit in the literature, that some procedure exists that permits to extract from texts in natural language non-trivial conclusions, and that makes no assumption on the quality or content of the arguments in the text.

Let $T$ be a set of possible texts in natural language and $p$ a procedure that transforms any text in $T$ into a set of undercut trees $\mathcal{U}$. Considering the classical logic approach first, we assume $p$ takes the following form: it first applies a set of possible interpretations of the text using a function $i$ to yield $\Delta, \Delta', …$, which are then used to produce undercut trees. Define $C$ as the classical logic approach defined above; applying $C$ to $i(t)$ thus results in a set of sets of undercut trees (one set for each $\Delta$).

For the conclusions to be non-trivial, we request that $\exists t \in T, \phi \in L(i(t)) \suchthat i(t) $ permits to deduce $\phi$ but $C(i(t))$ contains no tree with a warranted root arguing for $\phi$. Here $L(i(t))$ denotes the set of formulas that can be formed using the atoms in $\cup i(t)$.

For the interpretations to be neutral (in the sense of making no assumption on the quality or content of the arguments in the text), we request that $i$ satisfies the following, for all $t$. If $\exists \Delta \in i(t), \Phi \subseteq \Delta \suchthat MUS(\Phi)$, then $\exists \phi \in \Phi, \phi' \notin \Phi \suchthat MUS(\Phi \setminus \set{\phi} \cup \set{\phi'})$. $MUS(\Phi)$ means that $\Phi$ is a minimal unsatisfiable set.

Given a tree $(n, s)$ with $N = s[n]$ and $M \subseteq N$, define $D(M) = \set{S \subseteq N \suchthat s(M) \subseteq s^{-1}(S)}$ as the set of coalitions that attack all the attackers of $M$ (such a coalition is said to defend $M$). Say that $M$ is warranted iff for some finite sequence of the form $D_1 \in D(M), D_2 \in D(D_1), …, D_k \in D(D_{k - 1})$, we have $s(D_k) = \emptyset$.

To be more precise, the assumption we want to discuss here is the following.
Many articles start with a postulated known attack relation or logic representation of arguments. It is natural to wonder where this information might come from, and we suppose, although this is seldom discussed explicitly, that the assumption is that it is more or less easy to obtain such relations from the natural language form in which arguments generally arise in the wild. 
The postulate that we want to argue against here is that by inspecting the arguments and using common sense, either the attack relation can be seen immediately, or a logical representation of the arguments can unambigiously be obtained, itself yielding a non-trivial attack structure by logical manipulation.
By non-trivial, we mean here that the structures that are obtained do permit, at least sometimes, to discriminate between a claim and its negation, even though both the claim and its negation can be deduced from arguments in the text. (Intuitively, we want to exclude cases of obtaining entirely symmetric conclusions.)

Accordingly, we focus on the case of arguments given under natural language. 

We make the following hypothesis of robustness against interpretion. The set of possible interpretations is $I$. If an interpretation leads to $\Delta$, and some argument in the DB says $\Phi$ and is attacked by $\Psi$, and it is possible to deduce, from the DB, using elements from $\Phi$ and $\Psi$, a counter-argument, then it is included in the set of interpretations.

Undoubtedly, some situations let one determine easily the attack relation, by simple appeal to an obvious consensus. In the classical textbook example of Alice saying that “it will rain tomorrow because the weather forecast on the BBC said so” and Bob replying that “it will not rain tomorrow because the weather forecast on Channel 4 said so”, the situation is clear, and a simple appeal to consensus permits to solve any doubt to the contrary: give these arguments to any two persons, and they will agree that these arguments attack each other. Such trivial situations, although being possibly adequate for illustrative purposes of technical definitions, are however hardly representative of the complexity of the debates that an argumentation framework must be able to tackle. It seems reasonable to demand of argumentation theory to help us think about debates involving subtle, complicated arguments. For example, a framework could claim to be able to help a medical doctor take a decision about which treatment to prescribe, or help an individual to choose which political party she will vote for.

Our main claim is that there is no neutral formal way to determine an attack relation that is not symmetric. In other words, obtaining a non-symmetric attack relation requires the analyst to adopt a position in the debate, in the sense of considering some claims as “winning” over others in a way that cannot be justified in purely formal terms.

First, note that one can always interpret “kindly” any argument, by filling in (considering as implicit) any supplementary claim that is required to make it work. To illustrate, assume John says: “because the apple detached from the tree, it fell on the ground”. The antecedent is not sufficient to bring the consequent: in case of storm, for example, the apple could detach from the tree and (temporarily) not fall on the ground. Depending on the circumstances of the speech, however, it might be perfectly reasonable to assume that John really meant: “because the apple detached from the tree and there was no storm on that day, it fell on the ground”. Indeed, if a required element in a reasoning is missing, it may be because it is an implicit assumption (that perhaps John knows is shared by the audience, hence does not consider useful to say). Now, interpreting kindly any argument will constantly lead to abstain from any conclusion: any argument that attacks any other will be attacked in return. Indeed, imagine someone says: “as there was storm on that day, the apple did in fact not fell on the ground”. Interpreting John’s text kindly, we would conclude that these arguments attack each other, and will not be able to conclude anything.

If we want to avoid this unfortunate consequence of extreme permissivism, we must restrict which attacks we (as modelers) we consider as “plausible”. In the famous Tweety example, we consider likely that the defeasible rule Bird(x) => Fly(x) is abusively used for building the argument that Bird(Tweety) and therefore Fly(Tweety), in a case where Tweety is a penguin; and we obtain a not too permissive model where the argument Penguin(Tweety) attacks the first one. But we could, again, conclude otherwise: if, unknown to the modeler, the person uttering the sentence in favor of Tweety flying is talking about an island where there are only birds that fly, then the use of the rule is authorized, and the person saying that Tweety is a Penguin must be mistaken. It is a choice of the modeler to conclude otherwise.

This shows that one will either be overly permissive, or need a trusted source of knowledge (that defines a hierarchy of claims by plausibility, say).

Another way to view this tension is to observe that we need to interpret what John says: we do not know what is missing from his reasoning because he did not realize some supplementary hypothesis was required (and therefore possibly obtained a mistaken conclusion), or because he thought it was sufficiently clear for the audience that the hypothesis was holding in the context of his speech.

More generally, using the scheme requires to add a priori knowledge, which is usually left implicit in the literature but is nonetheless required. Defeasible rule: A implies B. Explicit rule: A and X imply B. Attack: not X. But we might instead make the first speaker win the argument by instead being more kind to him and considering that the mere fact that he used the rule A implies B means that he implicitly thought it clear that X hold as well. (This kind hypothesis may seem reasonable in some contexts, such as when the speaker is an expert in the relevant domain.) Also, it could be that there is another way to complete the defeasible rule A implies B, by saying A and Y imply B. In that case, not(X) is uneffective against the first speaker. When the modeler considers that an argument attacks another one, and not conversely, she is inevitably taking a (possibly implicit) position in favor of some of the arguments.

We can rephrase this by saying that a first and important reason to not consider the attack relation known a priori is that considering it known a priori seems to require to assume that the attack relation is objective, thus in particular, that whether an argument attacks another one does not depend on who is listening, or on a choice of interpretation. The objectivity assumption permits to declare that an argument “truly” attacks another one, even though some given person may fail to realize it or may even believe the contrary. 

Real-life debates feature omissions and implicit statements. It may be fundamentally undetermined (and not simply unknown) which statements exactly have been omitted so as to connect an argument to what the debater has said previously. The debater himself may be hard pressed to explain it, if asked: we human being may not always form fully precise statements mentally before uttering them, or if we do, we do not necessarily have access to the precise version of the statements. A mathematician might “feel” that a proposition is true long before knowing how to prove it. A person may intuitively “see” how one argument supports or attacks another one without being able to fill in all the gaps and make it a precise reasoning. Or there may be multiple reasonings that allow to fill in the gaps, and the debater may erroneously think that they are just different ways of expressing the same idea; whereas it could be that one phrasing features a mistake in reasoning whereas another one does not. It is the norm with philosophers debating of complex ideas to consider multiple versions of their opponent’s claim, trying to interpret them “kindly”, that is, filling what they see as gaps in their opponent’s reasoning in ways that make their opponent’s view point as solid as possible (cite Denett). It seems hard to justify that one of these versions in particular would objectively be the right version. And if there are indeed multiple interpretations of a statement that correspond to multiple precise arguments, it seems unlikely that they all would lead to the same attack relation when considered within a set of related arguments. Therefore, in some interesting cases, the attack relation is not objectively determined.

Another important reason to not consider the attack relation known a priori relates to the understanding of the attack relation itself. 
Even when arguably “what the debater means objectively” is well defined, one may, in some applications, be interested in what some given listener understands from the debate, rather than by what the debater means. 
This is an important distinction in our context because the attack relation representing what the listener understands may differ from the one representing what the debater means.
The listener may not know the meaning of some words used by the debaters, or she may understand them differently than what the debaters have in mind. 
The listener may not have the deductive power to understand what could otherwise be considered a trivial implication of the argument. 
The listener may lack some required knowledge.

Translating natural language arguments into a logic language does not constitute a solution to these problems, as the problems exist, unchanged, at the level of translation. When there are multiple ways of interpreting some implicit information present in an argument (as intended by the debater, or as understood by the listener), the modeler must choose one when translating it in a formal, precise language, with the risk of introducing an arbitrary choice or losing neutrality.

A practical argument is that encoding the arguments logically require important expertise, which may be unavailable or cost too much.

\commentOC{To discuss: which points require examples? How complex (toy examples VS realistic examples)? Consider an example of a logic encoding with different conclusions?}

Practical studies showed that rejected arguments are not necessarily to be interpreted as non-receivable, but rather as rough ideas that need to be refined \cite{EJDP2018, Bourguet2013} and can serve as initial pillars of great importance for the construction of the argumentation system. Talk about obtaining judgements of individuals, …

\section{what if not known a priori?}
We just argued that it may be relevant or convenient to not assume we know the attack relation. In this section we provide some ideas of subject of studies that do not require this assumption, that pertains to computer science, and does not require advanced natural language processing capabilities.

(To be continued.)
We consider that what counts is what the receiver of the argument says and we propose to study several aspects related to this perspective: how to find decisive arguments in this sense; is this consensual; what are appropriate methods, statistical or others; what are the protocols that must be used to gather arguments; how can we test that every arguments that are possibly relevant have been considered?

\section{a sketch of a possible approach}
Let people come to a website and argue and indicate which arguments theirs answer, then confront this to the opinion of other visitors
\commentRT{Raccrocher Nicolas ici ?}

\section{Others}
We should decide whether to include some of these points in the text or adding sections about them or dropping them.
\begin{itemize}
	\item possibly, contrast with persuasion?
	\item link to explainable AI (should focus on decisive arguments), exploitation of weaknesses of will or sub-conscious behavioral patterns (youtube autoplay; nudge; anchoring) VS reflective arguments (advocacy), and the like? Link to deliberative democracy?
	\item review existing experimental work in FAT? Other related works? Philosophical approaches (Rawls, Habermas)?
\end{itemize}

%\bibliography{bibl}

\end{document}
