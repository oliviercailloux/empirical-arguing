\RequirePackage[l2tabu, orthodox]{nag}
\documentclass[version=3.21, pagesize, twoside=off, bibliography=totoc, DIV=calc, fontsize=12pt, a4paper]{scrartcl}
\input{preamble/packages}
\input{preamble/redac}
\input{preamble/math_basics}
\input{preamble/math_mine}

%I find these settings useful in draft mode. Should be removed for final versions.
	%Which line breaks are chosen: accept worse lines, therefore reducing risk of overfull lines. Default = 200.
		\tolerance=2000
	%Accept overfull hbox up to...
		\hfuzz=2cm
	%Reduces verbosity about the bad line breaks.
		\hbadness 5000
	%Reduces verbosity about the underful vboxes.
		\vbadness=1300

\title{Study argument decisiveness empirically}
\author{Olivier Cailloux}
\affil{Université Paris-Dauphine, PSL Research University, CNRS, LAMSADE, 75016 PARIS, FRANCE\\
	\href{mailto:olivier.cailloux@dauphine.fr}{olivier.cailloux@dauphine.fr}
}
\author{Pierre Bisquert}
\affil{Affiliation}
\author{Nicolas Salliou}
\affil{Affiliation}
\author{Rallou Thomopoulos}
\affil{Affiliation}
\hypersetup{
	pdfsubject={Argumentation},
	pdfkeywords={Position paper, Formal argumentation theory, Review, Logic-based argumentation},
}

\begin{document}
\maketitle

\section{Introduction}
\label{sec:intro}
It is clear (?) that arguments that are not attacked are of prominent importance for society. Talk about obtaining judgements of individuals, …

Correspondingly, arguments that are not attacked are of prominent importance in many (otherwise different) formal approaches about argumentation. 

Note that “not attacked” depends on which set of arguments we look into; we consider for this discussion that the set of arguments encompasses every arguments that are possibly relevant to the topic at hand (and will come back to this). In this context, we call decisive the non-attacked arguments. 

NB in some examples, some arguments are left unattacked (for example, the gvt is not expected to answer every counter-argument). Also, in preference-based argumentation, arguments can be “unattacked subjectively”: specific preferences of an individual may invalidate an argument and leave only another argument as decisive.

Although some authors seem to acknowledge in passing that attack relations sometimes can’t be considered known (cite Besnard \& Hunter), as we will see, few works in FAT avoid this assumption. One may think of at least two reasons for this apparent gap. First, to the best of our knowledge, the reasons for doubting this assumption have not been analyzed clearly. Second, there might be a lack of an idea of where to start if one relaxes this assumption, perhaps fearing that this would lead to consider only questions that do not relate to computer science but rather to natural language, for example; or these questions may seem to be hopelessly complex and beyond reach of the current state of knowledge in natural language processing. We provide here (partial) answers to these two points.

\section{The usual perspective (in FAT?) about attacks}
Usually considered known a priori: logical representation; or simply given.

Also: preference based approaches. But this still considers an attack relation, and the preference is supplementary data on top of the attack relation. (TODO: check Besnard \& Hunter - Elements of Argumentation, Chapter 6: Considering the Audience.)

By attack relations, in plural, we mean the binary relations that are used to represent an argument “attacking” another one. There can be multiple such relations to distinguish the sort of attack: one that attempts to invalidate directly the conclusion, one that attempts to invalidate the reasoning, …

We want to distinguish two attitudes towards the attack relations. 

The most usual attitude is what we call the \emph{a priori} attitude: the attack relations are considered known. They are deducible using a systematic procedure from the arguments. This covers the case where the arguments are considered given under a logic form and this is used to deduce the attack relations; the case where the input itself is considered to be the attack relation; and the case where the input is considered a set of arguments in natural language (NL), and the attack relations are deduced from these NL arguments. (One can think of text form, video, …)

Another attitude consists in considering the attack relations as empirical. Under that view, the attacks are revealed by something else than the arguments themselves and a priori knowledge, such as the reactions of individuals to the arguments, as we will propose.

\section{Reasons not to consider it known}
We saw that most formal approaches in argumentation consider that the attack relation is (are) known. We here point out reasons to lift this assumption, thus, not consider that the attack relation can unambiguously be deduced by a logical representation of the arguments or can be known by trivial inspection of the arguments as in some of the classical textbook examples. We focus on the case of arguments given under natural language. Many articles start not from there but with a postulated known attack relation or logic representation of arguments; but this only moves the question further: how can one get these relations or logic form to start with? This is usually not discussed, but we assume that the implicit assumption is that it is more or less easy to obtain such relations from the natural language form in which arguments generally arise in the wild. This is the assumption that we want to discuss here.

%Undoubtedly, some situations let one determine easily the attack relation, by simple appeal to an obvious consensus. In the classical textbook example of Alice saying that “it will rain tomorrow because the weather forecast on the BBC said so” and Bob replying that “it will not rain tomorrow because the weather forecast on Channel 4 said so”, the situation is clear, and a simple appeal to consensus permits to solve any doubt to the contrary: give these arguments to any two persons, and they will agree that these arguments attack each other. Such trivial situations, although being possibly adequate for illustrative purposes of technical definitions, are however hardly representative of the complexity of the debates that an argumentation framework must be able to tackle. It seems reasonable to demand of argumentation theory to help us think about debates involving subtle, complicated arguments. For example, a framework could claim to be able to help a medical doctor take a decision about which treatment to prescribe.

First, note that one can always interpret “kindly” any argument, by filling in (considering as implicit) anything that is required to make it work. To illustrate, assume John says: “because the apple detached from the tree, it fell on the ground”. The antecedent is not sufficient to bring the consequent: in case of storm, for example, the apple could detach from the tree and (temporarily) not fall on the ground. Depending on the circumstances of the speech, however, it might be perfectly reasonable to assume that John really meant: “because the apple detached from the tree and there was no storm on that day, it fell on the ground”. Indeed, if a required element in a reasoning is missing, it may be because it is an implicit assumption (that perhaps John knows is shared by the audience, hence does not consider useful to say). Now, interpreting kindly any argument will constantly lead to abstain from any conclusion: any argument that attacks any other will be attacked in return. Indeed, imagine someone says: “as there was storm on that day, the apple did in fact not fell on the ground”. Interpreting John’s text kindly, we would conclude that these arguments attack each other, and will not be able to conclude anything.

If we want to avoid this unfortunate consequence of extreme permissivism, we must restrict which attacks we (as modelers) we consider as “plausible”. In the famous Tweety example, we consider likely that the defeasible rule Bird(x) => Fly(x) is abusively used for building the argument that Bird(Tweety) and therefore Fly(Tweety), in a case where Tweety is a penguin; and we obtain a not too permissive model where the argument Penguin(Tweety) attacks the first one. But we could, again, conclude otherwise: if, unknown to the modeler, the person uttering the sentence in favor of Tweety flying is talking about an island where there are only birds that fly, then the use of the rule is authorized, and the person saying that Tweety is a Penguin must be mistaken. It is a choice of the modeler to conclude otherwise.

This shows that one will either be overly permissive, or need a trusted source of knowledge (that defines a hierarchy of claims by plausibility, say).

Another way to view this tension is to observe that we need to interpret what John says: we do not know what is missing from his reasoning because he did not realize some supplementary hypothesis was required (and therefore possibly obtained a mistaken conclusion), or because he thought it was sufficiently clear for the audience that the hypothesis was holding in the context of his speech.

More generally, using the scheme requires to add a priori knowledge, which is usually left implicit in the literature but is nonetheless required. Defeasible rule: A implies B. Explicit rule: A and X imply B. Attack: not X. But we might instead make the first speaker win the argument by instead being more kind to him and considering that the mere fact that he used the rule A implies B means that he implicitly thought it clear that X hold as well. (This kind hypothesis may seem reasonable in some contexts, such as when the speaker is an expert in the relevant domain.) Also, it could be that there is another way to complete the defeasible rule A implies B, by saying A and Y imply B. In that case, not(X) is uneffective against the first speaker. When the modeler considers that an argument attacks another one, and not conversely, she is inevitably taking a (possibly implicit) position in favor of some of the arguments.

We can rephrase this by saying that a first and important reason to not consider the attack relation known a priori is that considering it known a priori seems to require to assume that the attack relation is objective, thus in particular, that whether an argument attacks another one does not depend on who is listening, or on a choice of interpretation. The objectivity assumption permits to declare that an argument “truly” attacks another one, even though some given person may fail to realize it or may even believe the contrary. 

Real-life debates feature omissions and implicit statements. It may be fundamentally undetermined (and not simply unknown) which statements exactly have been omitted so as to connect an argument to what the debater has said previously. The debater himself may be hard pressed to explain it, if asked: we human being may not always form fully precise statements mentally before uttering them, or if we do, we do not necessarily have access to the precise version of the statements. A mathematician might “feel” that a proposition is true long before knowing how to prove it. A person may intuitively “see” how one argument supports or attacks another one without being able to fill in all the gaps and make it a precise reasoning. Or there may be multiple reasonings that allow to fill in the gaps, and the debater may erroneously think that they are just different ways of expressing the same idea; whereas it could be that one phrasing features a mistake in reasoning whereas another one does not. It is the norm with philosophers debating of complex ideas to consider multiple versions of their opponent’s claim, trying to interpret them “kindly”, that is, filling what they see as gaps in their opponent’s reasoning in ways that make their opponent’s view point as solid as possible (cite Denett). It seems hard to justify that one of these versions in particular would objectively be the right version. And if there are indeed multiple interpretations of a statement that correspond to multiple precise arguments, it seems unlikely that they all would lead to the same attack relation when considered within a set of related arguments. Therefore, in some interesting cases, the attack relation is not objectively determined.

Another important reason to not consider the attack relation known a priori relates to the understanding of the attack relation itself. 
Even when arguably “what the debater means objectively” is well defined, one may, in some applications, be interested in what some given listener understands from the debate, rather than by what the debater means. 
This is an important distinction in our context because the attack relation representing what the listener understands may differ from the one representing what the debater means.
The listener may not know the meaning of some words used by the debaters, or she may understand them differently than what the debaters have in mind. 
The listener may not have the deductive power to understand what could otherwise be considered a trivial implication of the argument. 
The listener may lack some required knowledge.

Translating natural language arguments into a logic language does not constitute a solution to these problems, as the problems exist, unchanged, at the level of translation. When there are multiple ways of interpreting some implicit information present in an argument (as intended by the debater, or as understood by the listener), the modeler must choose one when translating it in a formal, precise language, with the risk of introducing an arbitrary choice or losing neutrality.

A practical argument is that encoding the arguments logically require important expertise, which may be unavailable or cost too much.

\commentOC{To discuss: which points require examples? How complex (toy examples VS realistic examples)? Consider an example of a logic encoding with different conclusions?}

\section{what if not known a priori?}
We just argued that it may be relevant or convenient to not assume we know the attack relation. In this section we provide some ideas of subject of studies that do not require this assumption, that pertains to computer science, and does not require advanced natural language processing capabilities.

(To be continued.)
We consider that what counts is what the receiver of the argument says and we propose to study several aspects related to this perspective: how to find decisive arguments in this sense; is this consensual; what are appropriate methods, statistical or others; what are the protocols that must be used to gather arguments; how can we test that every arguments that are possibly relevant have been considered?

\section{a sketch of a possible approach}
Let people come to a website and argue and indicate which arguments theirs answer, then confront this to the opinion of other visitors

\section{Others}
We should decide whether to include some of these points in the text or adding sections about them or dropping them.
\begin{itemize}
	\item possibly, contrast with persuasion?
	\item link to explainable AI (should focus on decisive arguments), exploitation of weaknesses of will or sub-conscious behavioral patterns (youtube autoplay; nudge; anchoring) VS reflective arguments (advocacy), and the like? Link to deliberative democracy?
	\item review existing experimental work in FAT? Other related works? Philosophical approaches (Rawls, Habermas)?
\end{itemize}

%\bibliography{bibl}

\end{document}
